{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a35cacd7",
   "metadata": {},
   "source": [
    "# Live Weapon Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89262688",
   "metadata": {},
   "source": [
    "The dataset can be downloaded at https://www.kaggle.com/datasets/ankan1998/weapon-detection-dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68836e1e",
   "metadata": {},
   "source": [
    "The data is stored in XML format. Let's use the XMLTree API to extract the features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be317149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "# create a csv: filename, width, height, depth, xmin, ymin, xmax, ymax\n",
    "text = ''\n",
    "def write_to_csv(filepath:str, output_path:str) -> None:\n",
    "    \"\"\"\n",
    "\n",
    "    Writes elements from an XML file to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str): Filepath pointing to the XML file\n",
    "        output_path (str): Name of the CSV file to write\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    tree = ET.parse(filepath)\n",
    "    root = tree.getroot()\n",
    "        \n",
    "    # write contents\n",
    "    text = ''\n",
    "    for child in root:\n",
    "        if child.tag == 'filename':\n",
    "            text += str(child.text)\n",
    "        if child.tag == 'size':\n",
    "            # 0 = width, 1 = height, 2 = depth\n",
    "            for i in range(3):\n",
    "                text += ',' + str(child[i].text)\n",
    "        if child.tag == 'object':\n",
    "            text += ',' + str(child[0].text)\n",
    "            # 0 = xmin, 1 = ymin, 2 = xmax, 3 = ymax\n",
    "            for i in range(4):\n",
    "                text += ',' + str(child[4][i].text)\n",
    "            # There may be multiple bounding boxes\n",
    "            # For now, only consider the first one\n",
    "            break\n",
    "\n",
    "    with open(output_path, 'a') as csvfile:\n",
    "        csvfile.write(text)\n",
    "        csvfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c6ebf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "def resize_images(images_path:str, resized_width:int, resized_height:int, save=False) -> tuple:\n",
    "    \"\"\"\n",
    "    \n",
    "    Resizes images to a given width and height.\n",
    "\n",
    "    Parameters:\n",
    "        images_path (str): Filepath containing the images to resize.\n",
    "        resized_width (int): Width to resize the images.\n",
    "        resized_height (int): Height to resize the images.\n",
    "\n",
    "    Returns:\n",
    "        tuple: NumPy arrays containing the resized images and generated labels.\n",
    "    \n",
    "    \"\"\"\n",
    "    if save:\n",
    "        os.makedirs('datasets/images_resized/', exist_ok=True)\n",
    "    # Resize images\n",
    "    resized_images = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(images_path):\n",
    "        file_path = os.path.join(images_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            with Image.open(file_path) as img:\n",
    "                # With Scikit-Image:\n",
    "                # img_data = np.asarray(img)\n",
    "                # resized = resize(img_data, (resized_width, resized_height))\n",
    "                # resized_images.append(resized)\n",
    "\n",
    "                # With PyTorch:\n",
    "                resize_transform = transforms.Resize((resized_height, resized_width))\n",
    "                resized = resize_transform(img)\n",
    "\n",
    "                if save:\n",
    "                    # Saves resized images\n",
    "                    resized.save('datasets/images_resized/' + filename)\n",
    "                    count += 1\n",
    "                    \n",
    "                resized_images.append(resized)\n",
    "\n",
    "    return resized_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67147ceb",
   "metadata": {},
   "source": [
    "Store the data in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a16fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weapons.csv', 'a') as csvfile:\n",
    "    header = 'Filename,Width,Height,Depth,Name,Xmin,Ymin,Xmax,Ymax'\n",
    "    csvfile.write(header)\n",
    "    csvfile.write('\\n')\n",
    "\n",
    "with open('weapons_test.csv', 'a') as csvfile:\n",
    "    header = 'Filename,Width,Height,Depth,Name,Xmin,Ymin,Xmax,Ymax'\n",
    "    csvfile.write(header)\n",
    "    csvfile.write('\\n')\n",
    "\n",
    "path = 'datasets/Sohas_weapon-Detection/annotations/xmls/'\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    file_path = os.path.join(path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        write_to_csv(file_path, 'weapons.csv')\n",
    "\n",
    "test_path = 'datasets/Sohas_weapon-Detection/annotations_test/xmls/'\n",
    "\n",
    "for filename in os.listdir(test_path):\n",
    "    file_path = os.path.join(test_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        write_to_csv(file_path, 'weapons_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c45d37b",
   "metadata": {},
   "source": [
    "Since the data is separated into two subdirectories, let's combine them and we will split them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a1ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Get min dimensions\n",
    "weapons_data = pd.concat(\n",
    "    map(pd.read_csv, ['weapons.csv', 'weapons_test.csv']), ignore_index=True\n",
    ")\n",
    "min_width = weapons_data['Width'].min()\n",
    "min_height = weapons_data['Height'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01354cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves resized images\n",
    "images_path = 'datasets/images_full'\n",
    "img = resize_images(images_path, min_width, min_height, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b93eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get resized image data\n",
    "images_path ='datasets/images_resized'\n",
    "resized_images = resize_images(images_path, min_width, min_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bcdd4",
   "metadata": {},
   "source": [
    "## Prepare Image Data for the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a131a6",
   "metadata": {},
   "source": [
    "Split the image dataset into train, test, and valid subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b97a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "src = 'datasets/images_resized/'\n",
    "train_dest = os.path.join(src, 'train')\n",
    "os.makedirs(train_dest, exist_ok=True)\n",
    "test_dest = os.path.join(src, 'test')\n",
    "os.makedirs(test_dest, exist_ok=True)\n",
    "val_dest = os.path.join(src, 'val')\n",
    "os.makedirs(val_dest, exist_ok=True)\n",
    "\n",
    "num_images = 1472\n",
    "train_percentage = 0.70\n",
    "test_percentage = 0.20\n",
    "num_train = int(num_images * train_percentage)\n",
    "num_test = int(num_images * test_percentage)\n",
    "num_val = num_images - num_train - num_test\n",
    "\n",
    "count = 0\n",
    "for filename in os.listdir(src):\n",
    "    file_path = os.path.join(src, filename)\n",
    "    if os.path.isfile(file_path) and count < num_train: \n",
    "        # Ensure the file is a file and only move images up to train percentage\n",
    "        shutil.move(file_path, train_dest)\n",
    "    count += 1\n",
    "\n",
    "count = 0\n",
    "for filename in os.listdir(src):\n",
    "    file_path = os.path.join(src, filename)\n",
    "    if os.path.isfile(file_path) and count < num_test: \n",
    "        shutil.move(file_path, test_dest)\n",
    "    count += 1\n",
    "\n",
    "count = 0\n",
    "for filename in os.listdir(src):\n",
    "    file_path = os.path.join(src, filename)\n",
    "    if os.path.isfile(file_path) and count < num_val:\n",
    "        shutil.move(file_path, val_dest)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "052014b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classes/labels subdirectory that specify if the image has a weapon or not\n",
    "for filename in os.listdir(train_dest):\n",
    "    # Get the corresponding image file with the same name\n",
    "    results = weapons_data[weapons_data['Filename'] == filename]\n",
    "    # Check if the image contains a weapon\n",
    "    #print(results['Name'].values)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d220b1b3",
   "metadata": {},
   "source": [
    "Next, we will convert this image dataset into COCO format using this tutorial: https://medium.com/codable/convert-any-dataset-to-coco-object-detection-format-with-sahi-95349e1fe2b7. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83a9ea",
   "metadata": {},
   "source": [
    "After that, use Roboflow's RF-DETR object detection model and customize it for this dataset. The docs can be found here: https://rfdetr.roboflow.com/learn/train/#dataset-structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
